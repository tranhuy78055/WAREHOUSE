# WAREHOUSE
The process includes steps such as extracting data from the Cassandra database, loading it into HDFS, and processing it with Spark and Hive for cleaning. After that, the data is handled using PySpark and Scala, and finally, it is visualized as charts using Apache Superset.
