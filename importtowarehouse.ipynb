{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01e3dde0-7a46-4baf-b334-c6d802e180a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "090f2a99-8aed-4954-82c0-a8a28ed415a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/16 14:53:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Import to warehouse\") \\\n",
    "    .config(\"spark.master\", \"spark://192.168.1.105:7077\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1323013-12dc-4a18-b547-6eb868ea6345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu từ datalake \n",
    "df = spark.read.parquet(\"hdfs://192.168.1.105:9000/datalake/data1612\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3935fd60-db0a-4768-95c9-1ea890ab695c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+--------------+--------------------+-----------------+------+---------+----------------+\n",
      "| id|Age|Gender|EducationLevel|            JobTitle|YearsofExperience|Salary|  Country|            Race|\n",
      "+---+---+------+--------------+--------------------+-----------------+------+---------+----------------+\n",
      "|  0| 32|  Male|    Bachelor's|   Software Engineer|              5.0| 90000|       UK|           White|\n",
      "|  1| 28|Female|      Master's|        Data Analyst|              3.0| 65000|      USA|        Hispanic|\n",
      "|  2| 45|  Male|           PhD|      Senior Manager|             15.0|150000|   Canada|           White|\n",
      "|  3| 36|Female|    Bachelor's|     Sales Associate|              7.0| 60000|      USA|        Hispanic|\n",
      "|  4| 52|  Male|      Master's|            Director|             20.0|200000|      USA|           Asian|\n",
      "|  5| 29|  Male|    Bachelor's|   Marketing Analyst|              2.0| 55000|      USA|        Hispanic|\n",
      "|  6| 42|Female|      Master's|     Product Manager|             12.0|120000|      USA|           Asian|\n",
      "|  7| 31|  Male|    Bachelor's|       Sales Manager|              4.0| 80000|    China|          Korean|\n",
      "|  8| 26|Female|    Bachelor's|Marketing Coordin...|              1.0| 45000|    China|         Chinese|\n",
      "|  9| 38|  Male|           PhD|    Senior Scientist|             10.0|110000|Australia|      Australian|\n",
      "| 10| 29|  Male|      Master's|  Software Developer|              3.0| 75000|       UK|           Welsh|\n",
      "| 11| 48|Female|    Bachelor's|          HR Manager|             18.0|140000|       UK|           Asian|\n",
      "| 12| 35|  Male|    Bachelor's|   Financial Analyst|              6.0| 65000|    China|          Korean|\n",
      "| 13| 40|Female|      Master's|     Project Manager|             14.0|130000|      USA|African American|\n",
      "| 14| 27|  Male|    Bachelor's|Customer Service Rep|              2.0| 40000|   Canada|           Asian|\n",
      "| 15| 44|  Male|    Bachelor's|  Operations Manager|             16.0|125000|    China|         Chinese|\n",
      "| 16| 33|Female|      Master's|   Marketing Manager|              7.0| 90000|      USA|           Asian|\n",
      "| 17| 39|  Male|           PhD|     Senior Engineer|             12.0|115000|       UK|           Mixed|\n",
      "| 18| 25|Female|    Bachelor's|    Data Entry Clerk|              0.0| 35000|       UK|           Asian|\n",
      "| 19| 51|  Male|    Bachelor's|      Sales Director|             22.0|180000|Australia|           Asian|\n",
      "+---+---+------+--------------+--------------------+-----------------+------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Hiển thị dữ liệu để xác nhận\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca3a7a32-aa4a-483f-9999-685e7fcd9f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "620e9bce-42f3-4e66-8588-459542c8c4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Age: int, Gender: string, EducationLevel: string, JobTitle: string, YearsofExperience: double, Salary: int, Country: string, Race: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6001a7-9345-4f52-b3e9-5732f0b4695f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acc268d5-ae92-420f-8667-eeb5c421fd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/16 15:35:03 ERROR TaskSchedulerImpl: Lost executor 1 on 192.168.1.100: Worker shutting down\n",
      "23/12/16 15:35:35 ERROR TaskSchedulerImpl: Lost executor 2 on 192.168.1.106: Command exited with code 129\n",
      "23/12/16 15:35:54 ERROR TaskSchedulerImpl: Lost executor 5 on 192.168.1.106: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n"
     ]
    }
   ],
   "source": [
    "df.write.parquet(\"hdfs://192.168.1.105:9000/datawarehouse/spark/data1612\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21de8c10-cc0e-4e39-897c-99f04a95d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_rules = [\n",
    "    (df[\"EducationLevel\"] == \"Bachelor's Degree\", \"Bachelor's\"),\n",
    "    (df[\"EducationLevel\"] == \"Master's Degree\", \"Master's\"),\n",
    "    (df[\"EducationLevel\"] == \"phD\", \"PhD\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f844dc9-e364-4f59-bf3f-15c71034d2f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[MISSING_ATTRIBUTES.RESOLVED_ATTRIBUTE_APPEAR_IN_OPERATION] Resolved attribute(s) \"EducationLevel\" missing from \"id\", \"Age\", \"Gender\", \"EducationLevel\", \"JobTitle\", \"YearsofExperience\", \"Salary\", \"Country\", \"Race\" in operator !Project [id#0, Age#1, Gender#2, CASE WHEN (EducationLevel#3 = Master's Degree) THEN Master's ELSE EducationLevel#64 END AS EducationLevel#74, JobTitle#4, YearsofExperience#5, Salary#6, Country#7, Race#8]. Attribute(s) with the same name appear in the operation: \"EducationLevel\".\nPlease check if the right attribute(s) are used.;\n!Project [id#0, Age#1, Gender#2, CASE WHEN (EducationLevel#3 = Master's Degree) THEN Master's ELSE EducationLevel#64 END AS EducationLevel#74, JobTitle#4, YearsofExperience#5, Salary#6, Country#7, Race#8]\n+- Project [id#0, Age#1, Gender#2, CASE WHEN (EducationLevel#3 = Bachelor's Degree) THEN Bachelor's ELSE EducationLevel#3 END AS EducationLevel#64, JobTitle#4, YearsofExperience#5, Salary#6, Country#7, Race#8]\n   +- Relation [id#0,Age#1,Gender#2,EducationLevel#3,JobTitle#4,YearsofExperience#5,Salary#6,Country#7,Race#8] parquet\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m when\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m condition, value \u001b[38;5;129;01min\u001b[39;00m replacement_rules:\n\u001b[0;32m----> 3\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEducationLevel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43motherwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEducationLevel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:5170\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   5165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[1;32m   5166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   5167\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5168\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m   5169\u001b[0m     )\n\u001b[0;32m-> 5170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [MISSING_ATTRIBUTES.RESOLVED_ATTRIBUTE_APPEAR_IN_OPERATION] Resolved attribute(s) \"EducationLevel\" missing from \"id\", \"Age\", \"Gender\", \"EducationLevel\", \"JobTitle\", \"YearsofExperience\", \"Salary\", \"Country\", \"Race\" in operator !Project [id#0, Age#1, Gender#2, CASE WHEN (EducationLevel#3 = Master's Degree) THEN Master's ELSE EducationLevel#64 END AS EducationLevel#74, JobTitle#4, YearsofExperience#5, Salary#6, Country#7, Race#8]. Attribute(s) with the same name appear in the operation: \"EducationLevel\".\nPlease check if the right attribute(s) are used.;\n!Project [id#0, Age#1, Gender#2, CASE WHEN (EducationLevel#3 = Master's Degree) THEN Master's ELSE EducationLevel#64 END AS EducationLevel#74, JobTitle#4, YearsofExperience#5, Salary#6, Country#7, Race#8]\n+- Project [id#0, Age#1, Gender#2, CASE WHEN (EducationLevel#3 = Bachelor's Degree) THEN Bachelor's ELSE EducationLevel#3 END AS EducationLevel#64, JobTitle#4, YearsofExperience#5, Salary#6, Country#7, Race#8]\n   +- Relation [id#0,Age#1,Gender#2,EducationLevel#3,JobTitle#4,YearsofExperience#5,Salary#6,Country#7,Race#8] parquet\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "for condition, value in replacement_rules:\n",
    "    df = df.withColumn(\"EducationLevel\", when(condition, value).otherwise(df[\"EducationLevel\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c3425-8ac9-4768-8eec-8cb3e23109af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0916bf-c520-4e65-ab05-c83c29f161d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1503694e-53d4-4667-8792-e56002ace12c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc482e2-1dbd-4868-bee2-6f9e86355454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5223db50-eff5-4565-8bec-4a77fb0e710f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c145507-14d5-4b96-b5b6-3a09c30b7fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
